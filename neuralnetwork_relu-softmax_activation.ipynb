{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax activation function\n",
    "def softmax(val):\n",
    "    return np.exp(val)/np.sum(np.exp(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaky ReLU activation function\n",
    "def relu(val):\n",
    "    neg=[1 if i>0 else 0.01 for i in val[0]]\n",
    "    val=val*neg\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_layer: shape - (1,i)\n",
    "# weights: shape - (i,j)\n",
    "# return - output: shape - (1,j)\n",
    "def forward_propogation(i_layer, weights,bias,func):\n",
    "    output = np.matmul(i_layer,weights)+bias\n",
    "    result=func(output)\n",
    "#     print(output.shape)\n",
    "    return  result, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_val: shape - (1,j)\n",
    "# value: shape - (1,k)\n",
    "# target: shape - (1,k)\n",
    "# return: shape - (j,k)\n",
    "def output_weight_update(hidden_val,value,target):\n",
    "    return np.matmul(hidden_val.T,(target-value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_val: shape - (1,i)\n",
    "# weight_h_o: shape - (j,k)\n",
    "# threshold: shape - (1,j)\n",
    "# value: shape - (1,k)\n",
    "# target: shape - (1,k)\n",
    "# return: shape - (i,j)\n",
    "def hidden_weight_update(input_val,weight_h_o,value,target,threshold):\n",
    "    val=np.matmul(target-value,weight_h_o.T)\n",
    "    neg=[1 if i>0 else 0 for i in threshold[0]]\n",
    "    val=val*neg\n",
    "    return np.matmul(input_val.T,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(data,label, hidden_layer,learning_rate,epochs,bias):\n",
    "    ip_units=data.shape[1]\n",
    "    output_layer=label.shape[1]\n",
    "    \n",
    "    # initialize weights for both layers\n",
    "    weights_i_h=np.random.rand(ip_units,hidden_layer)\n",
    "    biases_h=np.zeros((1,hidden_layer),dtype='float64')\n",
    "#     biases_h=np.random.rand(1,hidden_layer)\n",
    "    weights_h_o=np.random.rand(hidden_layer,output_layer)\n",
    "    biases_o=np.zeros((1,output_layer),dtype='float64')\n",
    "#     biases_o=np.random.rand(1,output_layer)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        total_error=0.0\n",
    "        hidden=[]\n",
    "        for x,y in zip(data,label):\n",
    "\n",
    "            # forward propogation\n",
    "            input_val=x.reshape((1,len(x)))\n",
    "            target_val=y.reshape((1,len(y)))\n",
    "            hidden_activated_val,hidden_val =forward_propogation(input_val,weights_i_h,biases_h,relu)\n",
    "            hidden.append(hidden_activated_val)\n",
    "            output_val,_=forward_propogation(hidden_activated_val,weights_h_o,biases_o,softmax)\n",
    "\n",
    "            #calculate total error\n",
    "            total_error+= np.mean((output_val-target_val)**2)\n",
    "            \n",
    "            # calculate delta to update weights\n",
    "            delta_h_o= output_weight_update(hidden_activated_val,output_val,target_val)\n",
    "            delta_i_h= hidden_weight_update(input_val,weights_h_o,output_val,target_val,hidden_val)\n",
    "\n",
    "            # weights update\n",
    "            weights_h_o+=learning_rate*delta_h_o\n",
    "            weights_i_h+=learning_rate*delta_i_h\n",
    "\n",
    "        if i%int(epochs/10) is 0:\n",
    "            print(\"Epoch-\", str(i), \", Error - \", str(total_error))\n",
    "    print()\n",
    "    network={}\n",
    "    network['weight']=[weights_i_h,weights_h_o]\n",
    "    network['bias']=[biases_h,biases_o]\n",
    "    print(\"Training Accuracy for wine dataset: \",evaluate(network,data,np.argmax(label,axis=1)+1))\n",
    "    return network,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(network,data):\n",
    "    \n",
    "    predictions=[]\n",
    "    \n",
    "    for x in data:\n",
    "#         print(x)\n",
    "        input_val=x.reshape((1,len(x)))\n",
    "        i=0\n",
    "        func=relu\n",
    "        for j,n in enumerate(zip(network['weight'],network['bias'])):\n",
    "            if j==1:\n",
    "                func=softmax\n",
    "            input_val, _=forward_propogation(input_val,n[0],n[1],func)\n",
    "#             print(i,\"=\",input_val)\n",
    "            i+=1\n",
    "        predictions.append(input_val)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x, y):\n",
    "    output = predict(model, x)\n",
    "    predictions=[j==np.argmax(i)+1 for i,j in zip(output,y)]\n",
    "    return np.mean(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the dataset from a csv file\n",
    "def read_csv(filename):\n",
    "    with open(filename) as file:\n",
    "\n",
    "        data=[line[:-1].split(',') for line in file.readlines()]\n",
    "        data=np.array(data).astype('float64')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forms the output dataset to match the network output layer \n",
    "# where each output neuron corresponds to a particular class\n",
    "def make_output_data(data):\n",
    "    val={ 1:[1.0,0.0,0.0], 2:[0.0,1.0,0.0],3:[0.0,0.0,1.0]}\n",
    "    label=[val[i] for i in data[:,0].astype('int')]\n",
    "    return np.array(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class Classifier Neural Network\n",
    "\n",
    "A Multi-class classifier neural network that uses Cross-entropy loss, ReLU activation for hidden layer and Softmax activation for output layer.\n",
    "Wine dataset used for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_train=read_csv('train_wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_test=read_csv('test_wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output=make_output_data(wine_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_train=wine_train[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max normalization performed on the training and testing dataset\n",
    "nmax=np.max(np.vstack((wine_train,wine_test[:,1:])),axis=0)\n",
    "nmin=np.min(np.vstack((wine_train,wine_test[:,1:])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_wine_train=(wine_train - nmin)/(nmax-nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_wine_test=(wine_test[:,1:]-nmin)/(nmax-nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch- 0 , Error -  35.56075546015582\n",
      "Epoch- 2 , Error -  27.43573317943771\n",
      "Epoch- 4 , Error -  19.471182337800176\n",
      "Epoch- 6 , Error -  13.728868356983549\n",
      "Epoch- 8 , Error -  10.0269075294662\n",
      "Epoch- 10 , Error -  7.837526474298466\n",
      "Epoch- 12 , Error -  6.527555183649636\n",
      "Epoch- 14 , Error -  5.666061304688704\n",
      "Epoch- 16 , Error -  5.044585453200642\n",
      "Epoch- 18 , Error -  4.5662153627387205\n",
      "\n",
      "Training Accuracy for wine dataset:  0.9602649006622517\n"
     ]
    }
   ],
   "source": [
    "# Input Data\n",
    "# Output data\n",
    "# No. of neurons in the hidden layer\n",
    "# Learning rate\n",
    "# No. of epochs\n",
    "# Boolean indicating if bias is added to the network\n",
    "wine_network,wine_hidden=neural_net(norm_wine_train,train_output,4,0.01,20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on the test data\n",
    "pred=predict(wine_network,norm_wine_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for wine dataset:  0.9602649006622517\n",
      "Testing Accuracy for wine dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Training and testing accuracy for the network\n",
    "print(\"Training Accuracy for wine dataset: \",evaluate(wine_network,norm_wine_train,np.argmax(train_output,axis=1)+1))\n",
    "print(\"Testing Accuracy for wine dataset: \",evaluate(wine_network,norm_wine_test,wine_test[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
