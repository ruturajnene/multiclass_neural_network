{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies sigmoid function to the given value\n",
    "def sigmoid(val):\n",
    "    return 1/(1+np.exp(-val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_layer: shape - (1,i)\n",
    "# weights: shape - (i,j)\n",
    "# return - output: shape - (1,j)\n",
    "def forward_propagation(i_layer, weights,bias,activation_function):\n",
    "    output = np.matmul(i_layer,weights)+bias\n",
    "#     print(output.shape)\n",
    "    return np.apply_along_axis(activation_function,axis=0,arr=output).reshape(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value: shape - (1,k)\n",
    "# target: shape - (1,k)\n",
    "# return: shape - (1,k)\n",
    "def error_output_layer(value,target):\n",
    "    return value*(np.ones(value.shape)-value)*(target-value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_value: shape - (1,j)\n",
    "# weight_h_o: shape - (j,k)\n",
    "# error_o: shape - (1,k)\n",
    "# return: shape - (1,j)\n",
    "def error_hidden_layer(h_value,weight_h_o,error_o):\n",
    "    return h_value*(np.ones(h_value.shape)-h_value)*np.matmul(error_o,weight_h_o.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = learning rate\n",
    "# error: shape - (1,k)\n",
    "# layer_value: shape - (1,j)\n",
    "# return: shape - (j,k)\n",
    "def weight_increment(l,error,layer_value):\n",
    "    return l*np.matmul(layer_value.T,error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(data,label, hidden_layer,learning_rate,epochs,bias):\n",
    "    ip_units=data.shape[1]\n",
    "    output_layer= label.shape[1]\n",
    "    \n",
    "    # initialize weights for both layers\n",
    "    weights_i_h=np.random.rand(ip_units,hidden_layer)\n",
    "    biases_h=np.zeros((1,hidden_layer),dtype='float64')\n",
    "#     biases_h=np.random.rand(1,hidden_layer)\n",
    "    weights_h_o=np.random.rand(hidden_layer,output_layer)\n",
    "    biases_o=np.zeros((1,output_layer),dtype='float64')\n",
    "#     biases_o=np.random.rand(1,output_layer)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        total_error=0.0\n",
    "        hidden=[]\n",
    "        for x,y in zip(data,label):\n",
    "\n",
    "            # forward propagation\n",
    "            input_val=x.reshape((1,len(x)))\n",
    "            target_val=y.reshape((1,len(y)))\n",
    "            hidden_val=forward_propagation(input_val,weights_i_h,biases_h,sigmoid)\n",
    "            hidden.append(hidden_val)\n",
    "            output_val=forward_propagation(hidden_val,weights_h_o,biases_o,sigmoid)\n",
    "\n",
    "            #calculate total error\n",
    "            total_error+= np.mean((output_val-target_val)**2)\n",
    "            \n",
    "            #backpropagate error\n",
    "            error_o= error_output_layer(output_val,target_val)\n",
    "            error_h= error_hidden_layer(hidden_val,weights_h_o,error_o)\n",
    "\n",
    "            # calculate delta to update weights\n",
    "            delta_h_o=weight_increment(learning_rate,error_o,hidden_val)\n",
    "            delta_i_h=weight_increment(learning_rate,error_h,input_val)\n",
    "\n",
    "            # weights update\n",
    "            weights_h_o+=delta_h_o\n",
    "            weights_i_h+=delta_i_h\n",
    "\n",
    "            #biases_update\n",
    "            if bias:\n",
    "                biases_o+=learning_rate*error_o\n",
    "                biases_h+=learning_rate*error_h\n",
    "        \n",
    "        if i%int(epochs/10) is 0:\n",
    "            print(\"Epoch-\", str(i), \", Error - \", str(total_error))\n",
    "    print()\n",
    "    network={}\n",
    "    network['weight']=[weights_i_h,weights_h_o]\n",
    "    network['bias']=[biases_h,biases_o]\n",
    "    return network,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(network,data):\n",
    "    \n",
    "    predictions=[]\n",
    "    \n",
    "    for x in data:\n",
    "#         print(x)\n",
    "        input_val=x.reshape((1,len(x)))\n",
    "        i=0\n",
    "        for w,b in zip(network['weight'],network['bias']):\n",
    "            input_val=forward_propagation(input_val,w,b,sigmoid)\n",
    "#             print(i,\"=\",input_val)\n",
    "            i+=1\n",
    "        predictions.append(input_val)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x, y):\n",
    "    output = predict(model, x)\n",
    "    predictions=[j==np.argmax(i)+1 for i,j in zip(output,y)]\n",
    "    return np.mean(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Neural Network\n",
    "\n",
    "The network is trained to encode and decode the above set of values. The hidden values represent the encoding for the given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.zeros((8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    d[i][i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input for the autoencoder\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch- 0 , Error -  1.9024195469154666\n",
      "Epoch- 500 , Error -  0.2239381646062156\n",
      "Epoch- 1000 , Error -  0.06817561597190125\n",
      "Epoch- 1500 , Error -  0.061925344707223884\n",
      "Epoch- 2000 , Error -  0.05896859026884352\n",
      "Epoch- 2500 , Error -  0.05716115611474606\n",
      "Epoch- 3000 , Error -  0.05590205829376038\n",
      "Epoch- 3500 , Error -  0.05495240444669053\n",
      "Epoch- 4000 , Error -  0.05419693543577444\n",
      "Epoch- 4500 , Error -  0.053572607546353124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# d: input data\n",
    "# d: output data\n",
    "# 3: no. of neurons in the hidden layer\n",
    "# 5: learning rate\n",
    "# 5000: epochs\n",
    "# False: boolean to indicate if we add bias to the network\n",
    "encoder_net,h_val=neural_net(d,d,3,5,5000,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.002' '0.964' '0.998']]\n",
      "[['0.57' '0.999' '0.002']]\n",
      "[['0.999' '0.593' '0.001']]\n",
      "[['0.082' '0.999' '0.373']]\n",
      "[['0.086' '0.087' '0.077']]\n",
      "[['0.985' '0.002' '0.998']]\n",
      "[['0.312' '0.292' '0.999']]\n",
      "[['0.999' '0.098' '0.366']]\n"
     ]
    }
   ],
   "source": [
    "for i in h_val:\n",
    "    print(i.round(3).astype(\"str\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded= predict(encoder_net,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0']]\n",
      "[['0.0' '1.0' '0.0' '0.0' '0.1' '0.0' '0.0' '0.0']]\n",
      "[['0.0' '0.0' '1.0' '0.0' '0.1' '0.0' '0.0' '0.0']]\n",
      "[['0.0' '0.0' '0.0' '1.0' '0.1' '0.0' '0.0' '0.0']]\n",
      "[['0.1' '0.1' '0.1' '0.1' '0.4' '0.1' '0.1' '0.1']]\n",
      "[['0.0' '0.0' '0.0' '0.0' '0.0' '1.0' '0.0' '0.0']]\n",
      "[['0.0' '0.0' '0.0' '0.0' '0.1' '0.0' '1.0' '0.0']]\n",
      "[['0.0' '0.0' '0.0' '0.0' '0.1' '0.0' '0.0' '1.0']]\n"
     ]
    }
   ],
   "source": [
    "# The decoded input\n",
    "for i in decoded:\n",
    "    print(i.round(1).astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': [array([[-6.39534545,  3.2904699 ,  6.25659706],\n",
       "         [ 0.28316891,  6.60604693, -6.27302003],\n",
       "         [ 6.51223843,  0.37736802, -6.53894118],\n",
       "         [-2.41885852,  6.5426077 , -0.51814849],\n",
       "         [-2.36106372, -2.35203975, -2.47723954],\n",
       "         [ 4.15498852, -6.32787613,  6.19261575],\n",
       "         [-0.79281709, -0.88754096,  6.58025421],\n",
       "         [ 6.59764832, -2.21631032, -0.55031704]]),\n",
       "  array([[-35.8965406 , -10.01651115,   9.5277685 , -29.6061879 ,\n",
       "           -1.82773186,  -3.23383377, -22.81075552,  12.77597868],\n",
       "         [ -4.24505482,   9.49087241,  -9.73522425,  12.13113096,\n",
       "           -1.78835475, -35.93681841, -23.34667679, -29.36059578],\n",
       "         [  7.9538547 , -35.35004845, -35.61297912, -16.15066554,\n",
       "           -1.51751209,   7.04879267,  17.62296611, -16.99561661]])],\n",
       " 'bias': [array([[0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0.]])]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The network weights that can be used to encode/decode the input\n",
    "encoder_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Square Loss Neural network\n",
    "\n",
    "A Multi-class classifier neural network that uses square loss and sigmoid activation function.\n",
    "Wine dataset used for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the dataset from a csv file\n",
    "def read_csv(filename):\n",
    "    with open(filename) as file:\n",
    "\n",
    "        data=[line[:-1].split(',') for line in file.readlines()]\n",
    "        data=np.array(data).astype('float64')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forms the output dataset to match the network output layer \n",
    "# where each output neuron corresponds to a particular class\n",
    "def make_output_data(data):\n",
    "    val={ 1:[1.0,0.0,0.0], 2:[0.0,1.0,0.0],3:[0.0,0.0,1.0]}\n",
    "    label=[val[i] for i in data[:,0].astype('int')]\n",
    "    return np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_train=read_csv('train_wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_test=read_csv('test_wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output=make_output_data(wine_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_train=wine_train[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max normalization performed on the training and testing dataset\n",
    "nmax=np.max(np.vstack((wine_train,wine_test[:,1:])),axis=0)\n",
    "nmin=np.min(np.vstack((wine_train,wine_test[:,1:])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_wine_train=(wine_train - nmin)/(nmax-nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_wine_test=(wine_test[:,1:]-nmin)/(nmax-nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch- 0 , Error -  36.277762162275614\n",
      "Epoch- 3 , Error -  4.482604242341998\n",
      "Epoch- 6 , Error -  2.2189460138606223\n",
      "Epoch- 9 , Error -  1.637008941257083\n",
      "Epoch- 12 , Error -  1.3646482773837654\n",
      "Epoch- 15 , Error -  1.1461778301482337\n",
      "Epoch- 18 , Error -  0.9498653592789318\n",
      "Epoch- 21 , Error -  0.7122773133831778\n",
      "Epoch- 24 , Error -  0.552270169301544\n",
      "Epoch- 27 , Error -  0.32804417937479186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input Data\n",
    "# Output data\n",
    "# No. of neurons in the hidden layer\n",
    "# Learning rate\n",
    "# No. of epochs\n",
    "# Boolean indicating if bias is added to the network\n",
    "wine_network,wine_hidden=neural_net(norm_wine_train,train_output,4,2,30,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on the test data\n",
    "pred=predict(wine_network,norm_wine_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for wine dataset:  0.9470198675496688\n",
      "Testing Accuracy for wine dataset:  0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Training and testing accuracy for the network\n",
    "print(\"Training Accuracy for wine dataset: \",evaluate(wine_network,norm_wine_train,np.argmax(train_output,axis=1)+1))\n",
    "print(\"Testing Accuracy for wine dataset: \",evaluate(wine_network,norm_wine_test,wine_test[:,0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
